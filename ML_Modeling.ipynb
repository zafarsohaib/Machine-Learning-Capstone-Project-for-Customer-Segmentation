{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries here; add more as necessary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.impute import SimpleImputer\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from helper import *\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "mailout_train = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TRAIN.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dias = pd.read_excel(\"DIAS Attributes - Values 2017.xlsx\", header=1)\n",
    "dias['Attribute'] = dias['Attribute'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = mailout_train['RESPONSE']\n",
    "mailout_train.drop(['RESPONSE'], inplace=True, axis=1)\n",
    "mailout_train.drop(['LNR'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns with high percentage of missing values ['AGER_TYP', 'ALTER_HH', 'ALTER_KIND1', 'ALTER_KIND2', 'ALTER_KIND3', 'ALTER_KIND4', 'EXTSEL992', 'KBA05_BAUMAX', 'KK_KUNDENTYP', 'TITEL_KZ']\n",
      "label encoding CAMEO_DEU_2015\n",
      "label encoding D19_LETZTER_KAUF_BRANCHE\n",
      "Convert CAMEO_DEUG_2015 str to float\n",
      "Mapping OST_WEST_KZ categorical\n",
      "Splitting CAMEO_INTL_2015 Feature into 2 features FAMILY and WEALTH\n",
      "Splitting LP_LEBENSPHASE_FEIN into two features INCOME and AGE\n",
      "Splitting PRAEGENDE_JUGENDJAHRE into two DECADE and MOVEMENT\n",
      "Get the registeration year from EINGEFUEGT_AM\n",
      "Dropping unwanted columns ['CAMEO_INTL_2015', 'LP_LEBENSPHASE_FEIN', 'PRAEGENDE_JUGENDJAHRE', 'EINGEFUEGT_AM']\n",
      "Imputing missing values with most frequent value\n"
     ]
    }
   ],
   "source": [
    "mailout_train_eng = preprocess(mailout_train, dias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM\n",
      "LGBM: 0.713093 (0.016574)\n",
      "roc auc train score = 0.99\n",
      "roc auc validation score = 0.71\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl8VOX1+PHPyQIhiICgogKJVLACQUBRNllcMCh1QftDGluwgtK60RYrFuuCYtFaBbW1IoJWKWrhK1prtYAEUVFZDKBRRBRlUUFQtoRAkvP747kTJslkZkJyZybhvF+vec3c594757kzMCd3e46oKsYYY0w4SfHugDHGmMRnycIYY0xEliyMMcZEZMnCGGNMRJYsjDHGRGTJwhhjTESWLIw5RCLyXxEZEe9+GBMLlixMnSMiG0Tk3Hj3Q1UHq+rTfry3iBwpIlNE5CsR2SMin3nTLf2IZ0wkliyMCUFEUuIYuwGwEOgEZANHAr2B7cAZh/B+cdsWU39YsjD1iogMEZE8EflBRN4RkS5B88aLyHoR2S0i+SJyadC8kSLytog8JCI7gDu9trdE5AER+V5EvhCRwUHr5IrIqKD1wy17ooi86cVeICJ/FZFnq9iMXwBtgUtVNV9VS1V1q6reraqveu+nInJS0Ps/JSL3eK8HiMgmEblFRL4BZorIxyIyJGj5FBH5TkS6e9M9vc/rBxFZJSIDavI9mPrHkoWpN7wfvhnAtUAL4HHgZRFp6C2yHjgLaArcBTwrIscFvcWZwOfAMcCkoLa1QEvgfuBJEZEquhBu2X8C73v9uhP4eZhNORd4TVX3RN7qKrUCjgIygGuA2cDwoPnnA9+p6koROQH4D3CPt844YK6IHF2D+KaesWRh6pPRwOOq+p6qlnjnE4qAngCq+i9V3eL9pf48sI7yh3W2qOojqlqsqoVe25eq+oSqlgBPA8cBx1YRP+SyItIW6AHcrqr7VfUt4OUw29EC+PqQPoGDSoE7VLXI25Z/AheJSLo3/2deG8CVwKuq+qr32cwHlgMX1LAPph6xZGHqkwzgd96hlB9E5AegDXA8gIj8IugQ1Q9AZ9xeQMDGEO/5TeCFqhZ4L4+oIn5Vyx4P7AhqqypWwHZcoqmJbaq6L6g/nwEfAz/xEsZFHEwWGcBPK3xufWuhD6YesRNfpj7ZCExS1UkVZ4hIBvAEcA6wVFVLRCQPCD6k5NcQzF8DR4lIelDCaBNm+QXAPSLSWFX3VrFMAZAeNN0K2BQ0HWpbAoeikoB8L4GA+9yeUdXREbbDHMZsz8LUVakikhb0SMElgzEicqY4jUXkQhFpAjTG/YBuAxCRq3B7Fr5T1S9xh3XuFJEGItIL+EmYVZ7B/YDPFZEfi0iSiLQQkT+ISODQUB7wMxFJFpFsoH8UXXkOGAT8ioN7FQDP4vY4zvfeL807Sd66mptq6jFLFqauehUoDHrcqarLcectHgW+Bz4DRgKoaj7wF2Ap8C2QBbwdw/7mAL1wh5juAZ7HnU+pRFWLcCe5PwHmA7twJ8dbAu95i92ESzg/eO89L1IHVPVr3Pb39uIH2jcCFwN/wCXTjcDN2O+DCSJW/MiY2BOR54FPVPWOePfFmGjYXw7GxICI9BCRH3mHlLJxf8lH3BswJlHYCW5jYqMV8H+4y2I3Ab9S1Q/i2yVjomeHoYwxxkRkh6GMMcZEVG8OQzVr1kxPOumkyAv6ZO/evTRu3Dhu8ROhDxbf4lv8uhd/xYoV36lq5KFdVLVePDp06KDxtGjRorjGT4Q+WHyLb/HrXnxguUbxG+vbYSgRmSEiW0Xkwyrmi4g87I3Tvzow+qU3b4SIrPMeVlzGGGPizM9zFk/hxuKvymCgvfe4BngMQESOAu7AjeB5BnCHiDT3sZ/GGGMi8C1ZqOqbwI4wi1wM/MPbE3oXaOYNF30+MF9Vd6jq97g7WMMlHWOMMT6L59VQJ1B+5M1NXltV7Qlp1ppZZE7J5OzFZ5M5JZNZa2Yddn2w+PH/N2CM33y9z0JEMoFXVLXSgG0i8h/gT+rG9kdEFgK/B84GGqpqoOrXH4ECVf1LiPe4BncIi6OPPvq0F154wactCW3Btwt44NMHKCo9OMRPw6SGjOswjnOPjU2J6Hj3IR7xVZVSSinVUuZ/O5+HP3u4Uvzftf8d57U6z5f4weL9+Qf6MP2L6Wwt2soxDY9h1ImjYhY72J49ezjiiKpGb7f4iRp/4MCBK1T19EjLxTNZPA7kqupsb3otMCDwUNVrQy1XlZNPPlnXrl1bm92PKHNKJl/u/LJSe7Ikc3yT4wFQ3JUEgdfgXYEW9Dra5UKts7tod1l7sCRJ4pjGx5AsySRJEkmSRHKSe13dtsB0qLbX1r1GQXFBpfiNUhoxIHMAxaXFlGgJJaUltfa6REui+n5SklJISUohNSnVPSenlpsO1RaYjrie93pm3kx2799dKXbztObcNeCuasU8lOl/fvhPrvn3NRQcOPgdpKemM+0n08jJyonqc6qpWWtmMWHhBL7a+RVtm7Zl0jmTYhY7EeIH5ObmMmDAgJjHrWl8EUn4ZHEhcD2uGteZwMOqeoZ3gnsFELg6aiVwmqqGO/8Rl2SRdFdSyB9qgJFdRyJeqQRBCFTXLGsTKfc62uUqrjP1valV9m9099GUqvsLvERL3HNpSbXaAtNVtX24NeTFbgD0OL4HyUnJJEsyKUkp1X8tySQnhX894Y0JVcb/Q98/cKD0AMWlxRwo8Z696eDXFecFpsMtE2jbWbSzyvjxlJKUwsktTqZBcgMapjR0z8nuuco273VgXjRtC79YyL1L7mVfcVmdJRqlNOLBQQ8yrPOwcsk3WZLL/t3WlllrZlmyrGH8uCcLEZmN20toiRsS+g4gFUBV/+7VJn4Ud/K6ALhK3RDTiMgvccMlgytmMzNSvETas8homsGGsRsOiz5Y/NDx2xzZhpXXrgybjGpj+q7Fd1XZt6GnDGV/yX72l+ynqLjIPZcUhW3bX7Lfz48r6r24aNv+vfbf7D1QuT5UkwZNGHP6mEp/hAQ/B//hEa6tqvdISUph4RcLue+t+9hXcjBZpqWkcc/Aexh6ytCyfpclTC9G4JEkNTttXBvJMu7JItbikSwS5a+aePbB4sc3fm0nS1XlQOmBskQSnExCtWU/m13l3vVD5z8UcU+tXFuFvbZo2j7d/mmV25KWklZ22LJUS6v9WcSCIJUSSCBhVWwLlWxWbFlBUUnlsijV+f6jTRb1ZriPeAj8GMRzFzTefbD48Y0/6ZxJIZPVpHMqVZaNioiUHW6KRtumbatMVmN7jj2kPlRHtMlSVcud8wp1HizwXFxaHFVbSWkJ5z1zXpXJcubFM8viBD8C71epPcplg9tCJQqAr3Z+VSufbzDbs6gl8T65lQh9sPjxiR/PY+bx3rOKd/xEPQzqx56FjTprTB2Xk5XDhrEbeKP/G2wYuyHme7bTfjKNjKYZCEJG04yYHoaNd/xJ50wiPTW9XFtN9uwSOb4dhjLG1EhOVg45WTlx27OKZ/x4H4aMZXxLFsYYUwOHS7K0w1DGGGMismRhjDEmIksWxhhjIrJkYYwxJiJLFsYYYyKyZGGMMSYiX5OFiGSLyFqvzvb4EPMzRGShV4M7V0RaB80rEZE87/Gyn/00xhgTnm/3WYhIMvBX4DxctbtlIvKyquYHLfYArrTq0yJyNvAn4OfevEJV7epX/4wxxkTPzz2LM4DPVPVzVd0PPIerux2sI7DQe70oxHxjjDEJwM96FpcD2ao6ypv+OXCmql4ftMw/gfdUdaqIDAXmAi1VdbuIFAN5QDEwWVXnhYgR17KqweJdUjER+mDxLb7Fr3vxoy2r6sp1+vAAfgpMD5r+OfBIhWWOB/4P+ACYijtc1TQwz3tuB2wAfhQuXocOHTSeFi1aFNf4idAHi2/xLX7diw8s1yh+0/0cG2oT0CZoujWwJXgBVd0CDAUQkSOAy1R1Z9A8VPVzEckFugHrfeyvMcaYKvh5zmIZ0F5EThSRBsAVQLmrmkSkpUhZXcFbgRlee3MRaRhYBugDBJ8YN8YYE0O+JQtVLQauB14HPgZeUNWPRGSiiFzkLTYAWCsinwLHAoFB2E8BlovIKtyJ78la/ioqY4wxMeTrEOWq+irwaoW224NezwHmhFjvHSDLz74ZY4yJnt3BbYwxJiJLFsYYYyKyZGGMMSYiSxbGGGMismRhjDEmIksWxhhjIrJkYYwxJiJLFsYYYyKyZGGMMSYiSxbGGGMiSuSyqiNEZJ33GOFnP40xxoTnW7IIKqs6GFcRb7iIdKywWKCsahdgIq6sKiJyFHAHcCau4t4dItLcr74aY4wJL1HLqp4PzFfVHar6PTAfyPaxr8YYY8JIyLKqwFVAmqre4y33R6BQVR+oEMPKqiZQHyy+xbf4dS9+nS6rCtwM3Ba03B+B34WLZ2VV498Hi2/xLX7di09dLqsqIptwhZGC1831sa/GGGPCSMiyqrjqeoO88qrNgUFemzHGmDhIyLKqqroDuBuXcJYBE702Y4wxcZCQZVW9eTM4uKdhjDEmjuwObmOMMRFZsjDGGBORJQtjjDERWbIwxhgTkSULY4wxEVmyMMYYE5ElC2OMMRFZsjDGGBORJQtjjDERWbIwxhgTUbzLqrYVkUUi8oFXWvUCrz1TRApFJM97/N3PfhpjjAnPt7GhgsqqnocbrnyZiLysqvlBi92GG2DwMa/k6qtApjdvvap29at/xhhjohfvsqoKHOm9bkqFehfGGGMSQ7zLqh4H/A9oDjQGzlXVFSKSCXwEfArswlXNWxIihpVVTaA+WHyLb/HrXvy6Ulb1t3jlUoFeQD5ub6ch0MJrPw3YCBwZLp6VVY1/Hyy+xbf4dS8+UZZV9fMwVMSyqsDVwAsAqroUSANaqmqRqm732lcA64EOPvbVGGNMGHEtqwp8BZwDICKn4JLFNhE52jtBjoi0A9oDn/vYV2OMMWH4djWUqhaLSKCsajIwQ72yqrjdnpeB3wFPiMhvcCe7R6qqikg/YKKIFAMlwBi1sqrGGBM38S6rmg/0CbHeXGCun30zxhgTPbuD2xhjTESWLIwxxkRkycIYY0xEliyMMcZEZMnCGGNMRJYsjDHGRGTJwhhjTESWLIwxxkRkycIYY0xEliyMMcZEZMnCGGNMRAlZg9ubd6u33loROd/PfhpjjAkvIWtwe6+vADoBxwMLRKSDqpb41V9jjDFVS9Qa3BcDz3lFkL4APvPezxhjTBwkag3uR4F3VfVZb7kngf+q6pwKMawGdwL1weJbfItf9+LX9RrcfwWuDFruSeCycPGsBnf8+2DxLb7Fr3vxibIGt5/Fj6KtwZ0Nrga3iKQBLaNc1xhjTIwkZA1ub7krRKShiJyIq8H9vo99NcYYE0ZC1uAGPhKRF3CHpYqB69SuhDLGmLhJyBrc3rxJwCQ/+2eMMSY6dge3McaYiCxZGGOMiciShTHGmIgsWRhjjInIkoUxxpiILFkYY4yJyJKFMcaYiCxZGGOMiciShTHGmIiiThYi0ldErvJeH+2N2WSMMeYwEFWyEJE7gFuAW72mVODZKNaLVFb1IRHJ8x6fisgPQfNKguZVHIDQGGNMDEU7NtSlQDdgJYCqbhGRJuFWiKasqqr+Jmj5G7wYAYWq2jXK/hljjPFRtIeh9nujwSqAiDSOYp1oyqoGGw7MjrI/xhhjYiiqsqoiMg5XU+I84E/AL4F/quojYdaJWFY1aNkM4F2gdWAochEpBvJwQ5RPVtV5IdazsqoJ1AeLb/Etft2LX+tlVXGJ4s/AA8B5USwfsaxq0LxbKs4Djvee2wEbgB+Fi2dlVePfB4tv8S1+3YtPbZVV9c49vK6q5wLzq5GwqlMa9QrguuAGVd3iPX8uIrm48xnrqxHfGGNMLYl4zkLdYaECEWlazfeOpqwqInIy0BxYGtTWXEQaeq9b4gok5Vdc1xhjTGxEezXUPmCNiMwH9gYaVfXGqlbQ6Mqqgjux/Zy3OxRwCvC4iJTiEtpkDbqKyhhjTGxFmyz+4z2qRSOUVfWm7wyx3jtAVnXjGWOM8UdUyUJVn/YOJXXwmtaq6gH/umWMMSaRRJUsRGQA8DTuqiQB2ojICFV907+uGWOMSRTRHob6CzBIVdcCiEgH3A10p/nVMWOMMYkj2ju4UwOJAkBVP8WND2WMMeYwEO2exXIReRJ4xpvOAVb40yVjjDGJJto9i18BHwE3Ajfh7nkY41enjDHGRGnWLMjMpP/ZZ0Nmppv2QbR7FinAVFV9EMru6m7oS4+MMcZEZ9YsuOYaKChAAL780k0D5OTUaqhok8VC4FxgjzfdCPgf0LtWe2OMMXXNrFkwYQL9v/oK2raFSZMO/Ye6pAT27oU9e9yjqteB6alToaCg/HsUFMCECXFLFmmqGkgUqOoeEUmv1Z4YY0xdM2sWjB4NhYUH/7L/5S/hzTfh1FMr/7hHer1vX/Sxk5KgtDT0vK++qo2tKyfaZLFXRLqr6koAETkdKKz13hhjTKJQhe+/h02bYONG9xz82LgRPv3ULRds/36YNu3gtAg0bgxHHHHw+YgjoFkzOOGEg9MV5we/DjUvLQ1OPNElqIratq31jyPaZDEW+JeIbMEVQDoeGBZpJRHJBqbixoaarqqTK8x/CBjoTaYDx6hqM2/eCOA2b949qvp0lH01xhxODuUwkCps3151Egi8LqzwN3FSEhx/PLRuDVlZsHZt6PcXgW++cT/sjRq5aT9MmlR2zqJMerprr2Vhk4WI9AA2quoyEfkxcC0wFHgN+CLCuodcVlVEjgLuAE7HJacV3rrfV38TjTG+qs1j9ocSO9QJ3p074cwzq04CmzZBUVH590pOdn/pt24N3brBRRe518GPVq0gJehnMzOz6r/sjznGxw33BD7nCRPQr75CfPz8I+1ZPI47sQ3QC/gDcAPQFZgGXB5m3bKyqgAiEiirWtXoscNxCQLgfGC+qu7w1p0PZGNlV42pLBF/rCG6PpSWur/eA4+CgsqvQ7UFXj/xROgTvNddV74tNdUlgjZt4IwzYOjQ8kmgTRv3456cXL3tj+Ff9lXKyYGcHBbn5jJgwADfwoQtqyoiq1T1VO/1X4FtgVFiRSRPVbuGWfeQy6p6ZVzTVPUeb/4fgUJVfaDCelZWNYH6YPFjH/+YBQs4+YEHSA76K7mkYUPWjhvH1nPPDbNmCCUlJO/fT1KoR1FRyPZ206aRunt35bdKS2NHjx4k7d9P8r59Zesn79vn1t23j+SiIpIOHNp4pJqUREnDhiQHTixXnA98ePfdFB19NEVHH82BZs3cISQfHLNgAe2mT6fh1q0UHXMMn48aVf3Pvhb4XVY10p5FsoikqGoxcA7eD3OU61b1HYZyBTDHK7QU9bqqOg23h8PJJ5+sfmbVSHJ9zup1oQ8WPw7xR4yodDgluaiIjlOn0nHjRnd1TWGhe674qNheXFxr3Uret4+jv//eHa9v2tT9td2okXsEXodqi+Z1ejqSmup+gKo4DCQZGWTddluldl8MGAD33FP2/XcEOsYmcjl+//uL9IM/G1gsIt/hrn5aAiAiJwE7I6xbk7Kqm4ABFdbNjRDPmMPDtm2wYAG8/nrVl0ju2eMu30xLc49Gjdxzy5aV24If1W0LnBeoKCMD1qzx93OAxDgMdJgImyxUdZKILASOA/4XVM0uCXfuIpyysqrAZlxC+FnFhUKVVcVV17tXRJp704OAWyPEM6Z+2r8f3n3XJYfXX4eVK93VPEcd5X4YKx6zB/dj/UXYa1Bqx+TJ8f2xjuEJ3sNdNDW431XVF1U1uJzqp4F7LsKsVwwEyqp+DLwQKKsqIhcFLVqprKp3YvtuXMJZBkwMnOw25rCwfj387W9w8cXQogX07w/33ef+op84Ed57D7Zuddfzp1e4PzbWP9bTpkFGBiriktS0abH9sc7JgQ0bWPzGG7BhgyUKn0R7n8UhOdSyql77DGCGb50zJpHs2gWLFh3ce/j8c9d+4olw5ZUwaBCcfbY7/h8sEf6yjtHVOCa+fE0WxpgqlJa6w0mB5LB0qTvB3LixSwq/+Q2cfz6cdFLkG7rsx9rEgCULU/fF8z6D6tiyBf73P5cc5s93dxADdO8O48a55NC7NzRoEN9+GhOCJQtTt8VwiOawfQiVrPbtgyVLDu49fPihW/7YY+GCC1xyOO+82Nzpa0wNWbIwdduECaHv4P3Nb9yPcIMG7tGw4cHXVT0O5aatUMnqqqvcyeh161zCaNAA+vZ1beefD126+DdWkDE+sWRh6q79+0OPywPuXoRBg6r3fikpkRNKxaSzYEHlweYOHICPP4Zf/9olh/793bkIY+owSxam7jlwAJ5+Gu6+u+plWrWCOXPc3c3791f9ONT5BQXuuWKiCCgpcYVpjKknLFmYuqO4GJ591t1n8MUXbkC44cPhkUcq3xT2wAPQp4//fQo36qgx9Yg/I2sZU5tKSty5gY4d3fmA5s3hlVfcXc2TJ8f3prBJk+J7U5wxMWLJwiSu0lJ4/nno3NndmNaoEcybB8uXw4UXHjxJHM87eBPhDmZjYsCShUk8paUwd66rYXzFFe4qpX/9Cz74wA1/kWhXEtlwE+Yw4GuyEJFsEVkrIp+JyPgqlvl/IpIvIh+JyD+D2ktEJM97vOxnP02CUIWXX4bTToPLL3cnsmfPhtWr3bRP9QiMMZH5doI7mrKqItIeN5psH1X9XkSC704qDFdcydQjqvDf/8Ltt8OKFW6Ii2eecSevq1u5zBjjCz//VCsrq6qq+4FAWdVgo4G/Bmprq+pWH/tjEo2qG/aid293DmL7dpgxw92jcOWVliiMSSB+JosTgI1B05u8tmAdgA4i8raIvCsi2UHz0kRkudd+iY/9NPGwaBH06+dunNu82Z0UXrvWXe2UYld0G5NowtbgrtEbi/wUOL9CDe4zVPWGoGVeAQ4A/w9XDW8J0FlVfxCR41V1i4i0A94AzlHV9RViWA3uBOpDNPGbrl5N5syZNM/Lo6hlS77MyeHrCy5Aa2HwvLqw/Rbf4ida/GhrcKOqvjyAXsDrQdO3ArdWWObvwMig6YVAjxDv9RRwebh4HTp00HhatGhRXOMnQh/Cxn/nHdXzzlMF1VatVKdOVS0sjF38GLD4Fr8uxgeWaxS/6X4ehiorqyoiDXBlVSte1TQPGAggIi1xh6U+F5HmItIwqL0PkI+pe5YtcyOs9u4NeXnwl7+4KnA33uhqOBtj6gTfDg6rarGIBMqqJgMz1CuristkL3vzBolIPlAC3Kyq20WkN/C4iJTizqtM1qCrqEwd8MEHcMcd8O9/u1rRkyfD9dfbgHrG1FFxLavq7QL91nsEL/MOkOVn30wtCq7n0KoVnHCCu8u6WTO45x644QY48sh499IYUwN22YmpmYr1HL7+2j2GDnWXwVasGW2MqZMsWZjq27HD7TksX+72HEIN071ihSUKY+oRSxYmvD17YOVKd6J6+XL3vH595PW++sr/vhljYsaShTmoqAhWrXIJIZAcPv7YDewHrkbD6afDqFHQo4cbw6lrV6vnYMxhwJLF4aq4GPLzDyaGZctgzRo3eB+4+tU9ergB/Hr0cEni2GMrv8+kSWXnLMpYPQdj6h1LFjUVfCVQ27buRzLWQ1RH6kNpKaxbd/Aw0rJl7tLWwLmGpk1dMvjd79xzjx7Qpk10Q4EH4kyYgH71FRKvz8AY4ytLFjVR8UqgL7900xC7H8tQfRg9Gt5/3xULWrbMnWzeudMt36gRdO8O1157cI/hpJNqNvx3Tg7k5LA4N5cBAwbUwkYZYxKNJYuamDCh/OEXcNO//rU79h/4yzz4L/SKbTWd99BDlftQWAgPPwypqdClixvqu0cP9zjlFBuozxhTbfarURNVXfGzaxc88oh7HTxQY+B1xedo51WHCOzeDQ0bVn9dY4ypwJJFTbRtG/pKoIwMV17TL8HJIzMzdNJq29YShTGm1lidypqYNMld+RMsFlcCiRx83HtvfPpgjDmsJHIN7hEiss57jPCzn4csJ8cV7cnIQEXcHsW0abG9EigR+mCMqfcSsga3iBwF3AGcDiiwwlv3e7/6e8gS4UqgROiDMaZeS9Qa3OcD81V1hzdvPpCNMcaYuPCzrOrlQLaWL6t6pqpeH7TMPOBTXHGjZOBOVX1NRMYBaap6j7fcH4FCVX2gQgwrq5pAfbD4Ft/i17340ZZV9fNqqFC3/1bMTClAe2AAXg1uEekc5bqo6jRgGsDJJ5+s8TwEk5sAh4Di3QeLb/Etfv2N7+dhqE1Am6Dp1sCWEMu8pKoHVPULYC0ueUSzrjHGmBhJyBrcHCy32lxEmgODvDZjjDFxkJA1uAFE5G5cwgGYqKo7/OqrMcaY8BKyBrc3bwYww8/+GWOMiY7dwW2MMSYiSxbGGGMismRhjDEmIksWxhhjIrJkYYwxJiJLFsYYYyKyZGGMMSYiSxbGGGMismRhjDEmIksWxhhjIoprWVURGSki20Qkz3uMCppXEtRecQBCY4wxMRTXsqqe54MLIgUpVNWufvXPGGNM9OJdVtUYY0wdEO+yqiOBPwHbcOVVf6OqG715xUAeUAxMVtV5IWJYWdUE6oPFt/gWv+7FrytlVf8NzFbVIhEZAzwNnO3Na6uqW0SkHfCGiKxR1fXl3ixCWdUDBw6wadMm9u3bV/OtiaBp06akpaX5HieR+1Bf46elpdG6dWtSU1PDLlffy2pa/MM7vp/JImJp1EChI88TwH1B87Z4z5+LSC7QDSiXLCJ2YNMmmjRpQmZmJiKhclft2b17N02aNPE1RqL3oT7GV1W2b9/Opk2bOPHEE2v1vY2pS+JaVlVEjguavAj42GtvLiINvdctgT5AxRPjEe3bt48WLVr4nihM/SUitGjRIiZ7p8YksniXVb1RRC7CnZfYAYz0Vj8FeFxESnEJbXKIq6iiYonC1JT9GzIm/mVVbwVuDbHeO0CWn30zxhgTPbuDO8isNbPInJJJ0l1JZE7JZNaaWTV6v+3bt9O1a1e6du1Kq1atOOGEE8qm9+/fH9V7XHXVVaxduzbsMn/961+ZNatmfTXGmHB83bOoS2atmcU1/76GggMFAHy580urY39VAAAXgklEQVSu+fc1AORk5RzSe7Zo0YK8vDwA7rzzTo444gjGjRtXbhlVRVVJSgqdt2fOnBkxznXXXQe4E7yJJNK2GWPqjsMmWYx9bSx53+RVOf/dTe9SVFJUrq3gQAFXv3Q1T6x4IuQ6XVt1ZUr2lGr35bPPPuOSSy6hb9++vPfee7zyyivcddddrFy5ksLCQoYNG8btt7ujdX379uXRRx+lc+fOtGzZkjFjxvDf//6X9PR0XnrpJY455hhuu+02WrZsydVXX03fvn3p27cvb7zxBjt37mTmzJn07t2bvXv38otf/ILPPvuMjh07sm7dOqZPn07XruVvkr/55pv5z3/+Q0pKCoMHD+a+++7jm2++4dprr+WLL75ARJg2bRpnnnkm999/P//4xz8AuPbaaxk5cmTIbVu9ejUTJ06kqKiI9u3bM2PGDBo3blztz80YEz/2J5+nYqKI1F5T+fn5XH311XzwwQeccMIJTJ48meXLl7Nq1Srmz59Pfn7l8/k7d+6kf//+rFq1il69ejFjxoyQ762qvP/++/z5z39m4sSJADzyyCO0atWKVatWMX78eD744INK63377be8+uqrfPTRR6xevZpbb3Wnk6677jrOO+88Vq9ezYoVKzjllFN4//33mTVrFu+//z5Lly7lb3/7Gx9++GGlbUtNTWXy5MksXLiQlStX0qVLF6ZOnVpbH6MxJkYOmz2LSHsAmVMy+XLnl5XaM5pmkDsyt9b786Mf/YgePXqUTc+ePZsnn3yS4uJitmzZQn5+Ph07diy3TqNGjRg8eDAAp512GkuWLAn53kOHDi1bZsOGDQC89dZb3HLLLQCceuqpdOrUqdJ6Rx11FElJSYwePZoLL7yQIUOGAO5mn+eeew6AlJQUjjzySJYsWcJll11Geno6AJdccglLly7loosuKrdt77zzDvn5+fTu3RuA/fv307dv3+p/YMaYuLI9C8+kcyaRnpperi09NZ1J50zyJV7wYZh169YxdepU3njjDVavXk12dnbI6/obNGhQ9jo5OZni4uKQ792wYcNKy0QzrEtqairLly/nkksuYe7cuVx44YVl8ypePhru/YK3TVXJzs4mLy+PvLw88vPzmTZtWsS+GGMSiyULT05WDtN+Mo2MphkIQkbTDKb9ZNohn9yujl27dtGkSROOPPJIvv76a15//fVaj9G3b18CY2etWbMm5GGu3bt3s2vXLoYMGcJDDz1Udqhq4MCB/P3vfwegpKSEXbt20a9fP1588UUKCwvZs2cPL730UtneQ7DevXuzePFiPv/8cwD27t3LunXran37jDH+OmwOQ0UjJysnJsmhou7du9OxY0c6d+5Mu3bt6NOnT63HuOGGG/jFL35Bly5d6N69O507d6Zp06blltm5cydDhw6lqKiI0tJSHnzwQQAeffRRRo8ezeOPP05KSgqPP/44Z5xxBsOHDy873PSrX/2KTp068e2335Z7z2OPPZYnn3ySYcOGlV0ufO+999K+ffta30ZjjI8ClzfW9UeHDh20ovz8/Eptftm1a1fMYh1KHw4cOKCFhYWqqvrpp59qZmamHjhwIGbxY8HP+NH8W1q0aJFv8aNh8S3+ocCNqBHxN9b2LA4Te/bs4ZxzzqG4uBhVLdtLMMaYaPj6ayEi2cBU3NhQ01V1coX5I4E/A5u9pkdVdbo3bwRwm9d+j6o+7Wdf67tmzZqxYsWKeHfDGFNHJWRZVRE5CrgDOB1XA2OFt+73fvXXGGNM1RK1rOr5wHxV3eEliPlAtk/9NMYYE4GfyeIEYGPQ9CavraLLRGS1iMwRkUCxpGjXNcYYEwOJWlY1mnUr1uAmNze33PymTZvGbHC9kpKSuA/kF+8+1Of4+/btq/Tvq6I9e/ZEXMZPFt/i+xo/mkumDuUB9AJeD5q+Fbg1zPLJwE7v9XDg8aB5jwPDw8WrlUtnn31WNSNDVcQ9P/ts1KtWddnm119/rcOGDdN27drpKaecooMHD9a1a9dWr1817EO0MjIydNu2baqq2qtXr5DLjBgxQv/1r3+FjT9z5kzdvHlzWfvVV1+tH330UY36Fg27dNbiW/zqI8pLZxOyrCquut4gr7xqc2CQ1+afWbPgmmvgyy9B1T1fc41rP0SqyqWXXsqAAQNYv349+fn53HvvvZVuXCspKalp72vdO++8c8jrPvXUU2zZcrDc+vTp0yuNc5UIqhouxRhTmW/JQlWLgUBZ1Y+BF9Qrq+qVUgVXVvUjEVkF3IhXVlVVdwB34xLOMmCi13boxo6FAQOqflx9NRQUlF+noMC1V7XO2LFhQy5atIjU1FTGjBlT1ta1a1fOOusscnNzGThwID/72c/IynJFAR988EE6d+5M586dmTLFDXy4d+9eLrzwQk499VQ6d+7M888/D8D48ePp2LEjXbp0qVQjA+Cxxx7j97//fdn0U089xQ033AC4Qf9OO+00OnXqVOU4TUcccQTgEt71119Px44dufDCC9m6dWvZMhMnTqRHjx507tyZa665BlVlzpw5LF++nJycHLp27UphYSEDBgxg+fLlgBswMSsri86dO5cNbBiIN2HCBE499VR69uxZKaECLF68uKx4VLdu3coOOd1///1kZWXRu3dvxo8fD0BeXh49e/akS5cuXHrppXz/vbuQbsCAAfzhD3+gf//+TJ06lW3btnHZZZfRo0cPevTowdtvv131F2rM4Sya3Y+68Ih4GOqmm1T796/64fYnQj+qWuemm8rePtQhkKlTp+rYsWMrtau6Xcb09HT9/PPPVVV1+fLl2rlzZ92zZ4/u3r1bO3bsqCtXrtQ5c+boqFGjytb74YcfdPv27dqhQwctLS1VVdXvv/++Uh+2bt2qP/rRj8qms7OzdcmSJaqqun37dlVVLSgo0E6dOul3332nquUPQzVu3FhVVefOnavnnnuuFhcX6+bNm7Vp06Zlh6EC76OqeuWVV+rzzz+vqqr9+/fXZcuWlc0LTG/evFnbtGmjW7du1QMHDujAgQP1xRdfVFVVQF9++WVVVb355pv17rvvrvSZDRkyRN966y1VVd29e7ceOHBAX331Ve3Vq5fu3btXd+3aVdanrKwszc3NVVXVP/7xj3qT9131799ff/WrX5W95/Dhw8s+ly+//FJ//OMfh/y+7DCUxa+v8bE7uCuYEqFIUWamO/RUUUYG+HTS6IwzzuDEE08E3BDil156admIrUOHDmXJkiVkZ2czbtw4brnlFoYMGcJZZ51FcXExaWlpjBo1qtxQ4sGOPvpo2rVrx7vvvkv79u1Zu3Zt2ZhTDz/8MC+++CIAGzduZN26dbRo0SJkH998802GDx9OcnIyxx9/PGeffXbZvEWLFnH//fdTUFDAjh07OOmkk8Ju77JlyxgwYABHH300ADk5Obz55ptccsklNGjQoGw7TjvtNObPn19p/T59+vDb3/6WnJwchg4dSuvWrVmwYAFXXXUV6enp7N69m6OOOoqdO3fyww8/0L9/fwBGjBjBT3/607L3GTZsWNnrBQsWlBtUcdeuXezevZsmTZqE3RZjDjc26mzApEmQXn6IctLTXfsh6tSpU9i7pisO5R1Khw4dWLFiBVlZWdx6661MnDiRlJQU3n//fS677DLmzZtHdnY2JSUl9OnTh65du5ZV2Rs2bBgvvPACc+fO5dJLL0VEyM3NZcGCBSxdupRVq1bRrVu3kMOhB6s4PDm4q4N+/etfM2fOHNasWcPo0aMjvk9V2whuePRAnKqGXx8/fjzTp0+nsLCQnj178sknn6CqIfsXTvDnXlpaytKlS8uGUN+8ebMlCmNCsGQRkJMD06a5PQkR9zxtmms/RGeffTZFRUU88cTBsqzLli1j8eLFlZbt168f8+bNo6CggL179/Liiy9y1llnsWXLFtLT07nyyisZN24cK1euZM+ePezcuZMLLriAKVOmkJeXR3JyMm+//TZ5eXll1fGGDh3KvHnzmD17dtlf0zt37qR58+akp6fzySef8O6774bdhn79+vHcc89RUlLC119/zaJFiwDKEkPLli3Zs2cPc+bMKVunSZMmIS9hPfPMM1m8eDHfffcdJSUlzJ49u+yv/2isX7+erKwsbrnlFk4//XQ++eQTBg0axIwZMyjwzjft2LGDpk2b0rx587LiUM8880yVcQYNGsSjjz5aNh2omW6MKe/wOQwVjZycGiWHikSEF198kbFjxzJ58mTS0tLIzMxkypQpbN68udyy3bt3Z+TIkZxxxhkAjBo1im7duvH6669z8803k5SURGpqKo899hi7d+/m4osvZt++fagqDz30UMj4zZs3p2PHjuTn55e9b3Z2Nn//+9/p0qULJ598Mj179gy7DZdeeilvvPEGWVlZdOjQoexHt1mzZowePZqsrCwyMzPLVf0bOXIkY8aMoVGjRixdurSs/bjjjuNPf/oTAwcORFW54IILuPjiaG/qhylTprBo0SKSk5Pp2LEjgwcPpmHDhuTl5XH66aeTkpLCkCFDuPfee3n66acZM2YMBQUFtGvXjpkzZ4Z8z4cffpjrrruOLl26UFxcTL9+/cpqdxhjgkRzYqMuPGyI8vj3oT7HtxPcFr++xicB7rMwxhhTT1iyMMYYE1G9TxYa5gocY6Jh/4aMqefJIi0tje3bt9t/dnPIVJXt27eTlpYW764YE1f1+mqo1q1bs2nTJrZt2+Z7rH379sX9ByXefaiv8dPS0mjdunWtv68xdUm9Thapqalld0j7LTc3l27dusUkVqL24XCPb0x95uthKBHJFpG1IvKZiIwPs9zlIqIicro3nSkihSKS5z3swndjjImjuNfgFpEmuBFn36vwFutVtatf/TPGGBO9RKjBfTdwPxB+YCFjjDFx4+c5i1B1tM8MXkBEugFtVPUVEalYlOFEEfkA2AXcpqpLKgYILqsKFInIh7XW++prCXwXx/iJ0AeLb/Etft2LnxHNQnGrwS0iScBDeAWPKvgaaKuq20XkNGCeiHRS1V3l3kx1GjDNe7/lqnp6bXW+uuIdPxH6YPEtvsWvv/H9PAy1CWgTNN0a2BI03QToDOSKyAagJ/CyiJyuqkWquh1AVVcA64EOPvbVGGNMGHGrwa2qO1W1papmqmom8C5wkaouF5GjvRPkiEg7oD3wuY99NcYYE4Zvh6FUtVhEAjW4k4EZ6tXgxo1y+HKY1fsBE0WkGCgBxmjkGtyhi0nHTrzjQ/z7YPEtvsWvp/HFhsIwxhgTSb0eG8oYY0ztsGRhjDEmonqRLKIdVqQW480Qka3B93WIyFEiMl9E1nnPzX2M30ZEFonIxyLykYjcFMs+iEiaiLwvIqu8+Hd57SeKyHte/Oe9Cxt8IyLJIvKBiLwS6/giskFE1njD0Sz32mL5b6CZiMwRkU+8fwe9Yvj9nxw0FE+eiOwSkbEx3v7feP/2PhSR2d6/yVh+/zd5sT8SkbFem6/bX53fHXEe9n4TV4tI95rGr/PJQg4OKzIY6AgMF5GOPod9Csiu0DYeWKiq7YGF3rRfioHfqeopuEuOr/O2OVZ9KALOVtVTga5Atoj0BO4DHvLifw9c7VP8gJuAj4OmYx1/oKp2Dbq2PZb/BqYCr6nqj4FTcZ9DTOKr6lpvu7sCpwEFwIuxii8iJ+CGCDpdVTvjLqC5ghh9/yLSGRiNG6XiVGCIiLTH/+1/iuh/dwbjriJtj7tx+bEaR4+m9moiP4BewOtB07cCt8YgbibwYdD0WuA47/VxwNoYfgYv4cbginkfgHRgJe7u/O+AlFDfiw9xW3v/Oc4GXsHdBBrL+BuAlhXaYvL5A0cCX+BdoBLPf4PAIODtGG9/YHSIo3BXdL4CnB+r7x/4KTA9aPqPwO9jsf3R/u4AjwPDQy13qI86v2dB6GFFTohDP45V1a8BvOdjYhFURDKBbriBGGPWB+8QUB6wFZiPu3HyB1Ut9hbx+3uYgvsPWupNt4hxfAX+JyIrxA07A7H7/NsB24CZ3mG46SLSOIbxg10BzPZexyS+qm4GHgC+wo32sBNYQey+/w+BfiLSQkTSgQtwNyDH4/OvKmat/y7Wh2QRdliR+kxEjgDmAmO1wlAoflPVEnWHIVrjdsdPCbWYH7FFZAiwVd3d/WXNsYrv6aOq3XG7+9eJSD8fY1WUAnQHHlPVbsBe/D3kFZJ3TuAi4F8xjtscNyjpicDxQGPc91CRL9+/qn6MO+Q1H3gNWIU7NJxIav3/Q31IFpGGFYmVb0XkOADveaufwUQkFZcoZqnq/8WjDwCq+gOQizt30kxEAjd6+vk99AEuEjdMzHO4Q1FTYhgfVd3iPW/FHa8/g9h9/puATaoaGNZ/Di55xPr7HwysVNVvvelYxT8X+EJVt6nqAeD/gN7E9vt/UlW7q2o/YAewjjj8/wsTs9Z/F+tDsgg7rEgMvQyM8F6PwJ1H8IWICPAk8LGqPhjrPogbjqWZ97oR7j/vx8Ai4HK/46vqraraWt0wMVcAb6hqTqzii0hjcXVY8A7/DMIdmojJ56+q3wAbReRkr+kcID9W8YMM5+AhKGIY/yugp4ike/8XAtsfk+8fQESO8Z7bAkNxn0OsP3/CxHwZ+IV3VVRPYGfgcNUh8+MEUKwfuGOGn+KOm0+IQbzZuGOlB3AZ/GrcMfOFuL8wFgJH+Ri/L26XcjWQ5z0uiFUfgC7AB178D4HbvfZ2wPvAZ7hDEw1j8F0MAF6JZXwvzirv8VHg31yM/w10BZZ738E8oHmM46cD24GmQW2xjH8X8In37+8ZoGEs//0BS3AJahVwTiy2vzq/O7jDUH/1fhPX4K4cq1F8G+7DGGNMRPXhMJQxxhifWbIwxhgTkSULY4wxEVmyMMYYE5ElC2OMMRFZsjB1nnffx1veKKCXBLW/JCLHH8J7vecNo3FWhXljveEdqtu/iSJyboRlLpIYjJgcIm5XEbkg1nFN3WOXzpo6T0RuBApxd3O/pqp9ROQnQHdVvaua73UFMFhVR4SYtwF3vfp3IeYlq2rJIW1AHInISNw2XR/vvpjEZnsWpj44ADTC3ZhV6g35MBb4c1UriEiGiCz0xvpfKCJtRaQrcD9wgbg6DY2Clr8RNw7RIhFZ5LXt8fYa3gN6icjtIrLM28OZ5t1djIg8JSKXe683iMhdIrJSXD2MH3vtI0Xk0aDlHxaRd0Tk86B1k0Tkb+JqKLwiIq8G5lXYthtFJN/btue8tsbi6iEs8/aaLvZGPJgIDPO2d1jNvgZTn1myMPXBP3FDVL8G3An8GviHqhaEWedRb5kuwCzgYVXNA24HnldXr6EwsLCqPowbW2egqg70mhvjhos+U1XfAh5V1R7qaiw0AoZUEfs7dYMQPgaMq2KZ43B36g8BJnttQ3FDVGcBo3DDcIcyHujmbdsYr20CbliUHsBAXCJNrbC9z1fxfsZYsjB1n6ruVNUL1RUhWon7gZ0rIk+IqyYX6ke1Fy7JgBsuou8hhC7BDeYYMNA737EGN7hhpyrWCwz8uAL34x/KPFUtVdV84FivrS/wL6/9G9xYSKGsBmaJyJUcHA11EDBe3LDyuUAa0DbcxhkTzJKFqW9uBybhBrlbAfwSuDeK9Q7l5N2+wHkKEUkD/gZcrqpZwBO4H+RQirznEtxw4+GWgYPDTYcadjqUC3HjAp0GrPAOywlwmbcH0VVV26obatuYqFiyMPWGuNKWx6vqYtxAd6W4JBDqR/sd3Ii1ADnAW1GE2A00qWJeIMZ34uqMVDqXUAveAi7zzl0cixtEsRwRSQLaqOoiXHGoZsARwOvADUHnUbp5q4TbJmPKWLIw9ckk4Dbv9WxgJPAurqpaRTcCV4nIauDnuHrekUwD/hs4wR1MXV2PJ3AjfM7DDZ1f2+biRhv9EFc28z1clbhgycCz3qGwD3A1qX8A7sado1gtIh960+AOZXW0E9wmErt01pg6RESOUNU9ItICNxx3H+/8hTG+qup4qTEmMb3iFZ5qANxticLEiu1ZGGOMicjOWRhjjInIkoUxxpiILFkYY4yJyJKFMcaYiCxZGGOMiej/A7g8VbMrZtt2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f82591657f0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB: 0.681090 (0.012542)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc train score = 0.99\n",
      "roc auc validation score = 0.68\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f823d1bd2b0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 2min 25s, sys: 13.2 s, total: 1h 2min 38s\n",
      "Wall time: 1h 3min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = create_baseline_models()\n",
    "names, results = compare_models(mailout_train, target, models, curve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n",
      "RF: 0.609228 (0.021233)\n",
      "roc auc train score = 0.98\n",
      "roc auc validation score = 0.61\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb11c0a6748>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "SEED = 42\n",
    "models = []\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=250, random_state=SEED)))\n",
    "names, results = compare_models(mailout_train_eng, target, models, curve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LGBM; Mean-AUC: 0.7059; Std: 0.0229; Training time: 1.14 min\n",
      "Model: GB; Mean-AUC: 0.7526; Std: 0.0268; Training time: 4.73 min\n",
      "Model: RF; Mean-AUC: 0.6092; Std: 0.0212; Training time: 2.85 min\n",
      "Model: LogR; Mean-AUC: 0.6638; Std: 0.0196; Training time: 2.04 min\n",
      "Model: MLP; Mean-AUC: 0.5828; Std: 0.0293; Training time: 2.58 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGB; Mean-AUC: 0.6689; Std: 0.0271; Training time: 5.03 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.7059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GB</td>\n",
       "      <td>0.7526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.6092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogR</td>\n",
       "      <td>0.6638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.5828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.6689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model   Score\n",
       "0  LGBM  0.7059\n",
       "1    GB  0.7526\n",
       "2    RF  0.6092\n",
       "3  LogR  0.6638\n",
       "4   MLP  0.5828\n",
       "5   XGB  0.6689"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 16s, sys: 2.68 s, total: 18min 19s\n",
      "Wall time: 18min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = create_baseline_models() # unscaled\n",
    "names, results = compare_models(mailout_train_eng, target, models)\n",
    "baseline_score_df = pd.DataFrame({'Model':names, 'Score': results})\n",
    "display(baseline_score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_score_df = pd.DataFrame({'Model':['LGBM', 'SVC','LogR','GB','RF','MLP','XGB'], \n",
    "                                  'Score': [0.7059, 0.5197,0.6638,0.7526,0.6092,0.5828,0.6689]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LGBM; Mean-AUC: 0.6998; Std: 0.0265; Training time: 1.21 min\n",
      "Model: GB; Mean-AUC: 0.7526; Std: 0.0268; Training time: 4.72 min\n",
      "Model: RF; Mean-AUC: 0.6106; Std: 0.0199; Training time: 2.89 min\n",
      "Model: LogR; Mean-AUC: 0.6594; Std: 0.0155; Training time: 1.33 min\n",
      "Model: MLP; Mean-AUC: 0.6232; Std: 0.0216; Training time: 3.9 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGB; Mean-AUC: 0.6689; Std: 0.0271; Training time: 5.03 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "      <th>Standard-Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.6998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GB</td>\n",
       "      <td>0.7526</td>\n",
       "      <td>GB</td>\n",
       "      <td>0.7526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.6092</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.6106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogR</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>LogR</td>\n",
       "      <td>0.6594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.5828</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.6232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.6689</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.6689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model   Score Standard-Model   Score\n",
       "0  LGBM  0.7059           LGBM  0.6998\n",
       "1    GB  0.7526             GB  0.7526\n",
       "2    RF  0.6092             RF  0.6106\n",
       "3  LogR  0.6638           LogR  0.6594\n",
       "4   MLP  0.5828            MLP  0.6232\n",
       "5   XGB  0.6689            XGB  0.6689"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 58s, sys: 2.94 s, total: 19min 1s\n",
      "Wall time: 19min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#models = get_scaled_models('standard') # Standard Scaled\n",
    "models = create_baseline_models() \n",
    "mailout_train_standard = feature_scaling(mailout_train_eng, 'standard')\n",
    "names, results = compare_models(mailout_train_standard, target, models) # Using Standard Scaled Data\n",
    "standard_scaler_score_df = pd.DataFrame({'Standard-Model':names, 'Score': results})\n",
    "score_df = pd.concat([baseline_score_df, standard_scaler_score_df], axis=1)\n",
    "display(score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LGBM; Mean-AUC: 0.7058; Std: 0.0185; Training time: 0.75 min\n",
      "Model: GB; Mean-AUC: 0.7526; Std: 0.0268; Training time: 4.68 min\n",
      "Model: RF; Mean-AUC: 0.6115; Std: 0.0205; Training time: 2.75 min\n",
      "Model: LogR; Mean-AUC: 0.6731; Std: 0.0176; Training time: 0.58 min\n",
      "Model: MLP; Mean-AUC: 0.6007; Std: 0.0134; Training time: 9.07 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGB; Mean-AUC: 0.6689; Std: 0.0271; Training time: 4.97 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "      <th>Standard-Model</th>\n",
       "      <th>Score</th>\n",
       "      <th>MinMax-Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.6998</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.7058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GB</td>\n",
       "      <td>0.7526</td>\n",
       "      <td>GB</td>\n",
       "      <td>0.7526</td>\n",
       "      <td>GB</td>\n",
       "      <td>0.7526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.6092</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.6106</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.6115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogR</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>LogR</td>\n",
       "      <td>0.6594</td>\n",
       "      <td>LogR</td>\n",
       "      <td>0.6731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.5828</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.6232</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.6007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.6689</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.6689</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.6689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model   Score Standard-Model   Score MinMax-Model   Score\n",
       "0  LGBM  0.7059           LGBM  0.6998         LGBM  0.7058\n",
       "1    GB  0.7526             GB  0.7526           GB  0.7526\n",
       "2    RF  0.6092             RF  0.6106           RF  0.6115\n",
       "3  LogR  0.6638           LogR  0.6594         LogR  0.6731\n",
       "4   MLP  0.5828            MLP  0.6232          MLP  0.6007\n",
       "5   XGB  0.6689            XGB  0.6689          XGB  0.6689"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22min 41s, sys: 2.61 s, total: 22min 44s\n",
      "Wall time: 22min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = create_baseline_models() \n",
    "mailout_train_minmax = feature_scaling(mailout_train_eng, 'minmax')\n",
    "names, results = compare_models(mailout_train_minmax, target, models) # Using MinMax Scaled Data\n",
    "min_max_score_df = pd.DataFrame({'MinMax-Model':names, 'Score': results})\n",
    "score_df = pd.concat([baseline_score_df, standard_scaler_score_df, min_max_score_df], axis=1)\n",
    "display(score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.70594</td>\n",
       "      <td>standardLGBM</td>\n",
       "      <td>0.700357</td>\n",
       "      <td>minmaxLGBM</td>\n",
       "      <td>0.705819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model    Score         Model     Score       Model     Score\n",
       "0  LGBM  0.70594  standardLGBM  0.700357  minmaxLGBM  0.705819"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "      <th>Standard-Model</th>\n",
       "      <th>Score</th>\n",
       "      <th>MinMax-Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.6998</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.7058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GB</td>\n",
       "      <td>0.7526</td>\n",
       "      <td>GB</td>\n",
       "      <td>0.7526</td>\n",
       "      <td>GB</td>\n",
       "      <td>0.7526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.6092</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.6106</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.6115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogR</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>LogR</td>\n",
       "      <td>0.6594</td>\n",
       "      <td>LogR</td>\n",
       "      <td>0.6731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.5828</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.6232</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.6007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.6689</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.6689</td>\n",
       "      <td>XGB</td>\n",
       "      <td>0.6689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model   Score Standard-Model   Score MinMax-Model   Score\n",
       "0  LGBM  0.7059           LGBM  0.6998         LGBM  0.7058\n",
       "1    GB  0.7526             GB  0.7526           GB  0.7526\n",
       "2    RF  0.6092             RF  0.6106           RF  0.6115\n",
       "3  LogR  0.6638           LogR  0.6594         LogR  0.6731\n",
       "4   MLP  0.5828            MLP  0.6232          MLP  0.6007\n",
       "5   XGB  0.6689            XGB  0.6689          XGB  0.6689"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning of LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train_minmax = feature_scaling(mailout_train_eng, 'minmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS = 200\n",
    "SEED = 42\n",
    "bayes_cv_tuner_lgbm = BayesSearchCV(\n",
    "    estimator = lgb.LGBMClassifier(\n",
    "        application='binary',\n",
    "        metric='auc',\n",
    "        n_jobs=-1,\n",
    "        verbose=-1,\n",
    "    ),\n",
    "    search_spaces = {\n",
    "        'learning_rate': (0.001, 0.25, 'uniform'),\n",
    "        'n_estimators': (10, 200),\n",
    "        'max_depth': (2, 10),\n",
    "        'num_leaves': (20, 100),\n",
    "        'colsample_bytree':(0.9, 1.0, 'uniform'),\n",
    "        'max_bin': (500, 1000),\n",
    "        #'min_data_in_leaf':(20, 100),\n",
    "        'min_child_samples': (1, 50),\n",
    "        'reg_alpha': (1e-9, 10.0, 'log-uniform'),\n",
    "        'reg_lambda': (1e-10, 1.0, 'log-uniform'),      \n",
    "        'scale_pos_weight': (1,150, 'uniform'),\n",
    "\n",
    "},    \n",
    "    scoring = 'roc_auc',\n",
    "    cv = StratifiedKFold(\n",
    "        n_splits=5,\n",
    "        shuffle=True,\n",
    "        random_state=SEED\n",
    "    ),\n",
    "    n_jobs = -1,\n",
    "    n_iter = ITERATIONS,  \n",
    "    verbose = 0,\n",
    "    refit = True,\n",
    "    random_state = SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_param(x):\n",
    "    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
    "    \n",
    "    # Get all the models tested so far in DataFrame format\n",
    "    all_models = pd.DataFrame(bayes_cv_tuner_lgbm.cv_results_)    \n",
    "    \n",
    "    # Get current parameters and the best parameters    \n",
    "    best_params = pd.Series(bayes_cv_tuner_lgbm.best_params_)\n",
    "    print('Model #{}\\nBest ROC-AUC: {}\\nBest params: {}\\n'.format(\n",
    "        len(all_models),\n",
    "        np.round(bayes_cv_tuner_lgbm.best_score_, 4),\n",
    "        bayes_cv_tuner_lgbm.best_params_\n",
    "    ))\n",
    "    \n",
    "    # Save all model results\n",
    "    clf_name = bayes_cv_tuner_lgbm.estimator.__class__.__name__\n",
    "    all_models.to_csv(clf_name+\"_cv_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #1\n",
      "Best ROC-AUC: 0.6089\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9410103958853314), ('learning_rate', 0.18220371005115393), ('max_bin', 966), ('max_depth', 5), ('min_child_samples', 34), ('n_estimators', 89), ('num_leaves', 48), ('reg_alpha', 0.024833752122391455), ('reg_lambda', 1.10823818604873e-07), ('scale_pos_weight', 98)])\n",
      "\n",
      "Model #2\n",
      "Best ROC-AUC: 0.6183\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9837388355553285), ('learning_rate', 0.2209455040678347), ('max_bin', 652), ('max_depth', 10), ('min_child_samples', 43), ('n_estimators', 22), ('num_leaves', 31), ('reg_alpha', 3.43458268604567e-06), ('reg_lambda', 0.00022766224742996492), ('scale_pos_weight', 143)])\n",
      "\n",
      "Model #3\n",
      "Best ROC-AUC: 0.6183\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9837388355553285), ('learning_rate', 0.2209455040678347), ('max_bin', 652), ('max_depth', 10), ('min_child_samples', 43), ('n_estimators', 22), ('num_leaves', 31), ('reg_alpha', 3.43458268604567e-06), ('reg_lambda', 0.00022766224742996492), ('scale_pos_weight', 143)])\n",
      "\n",
      "Model #4\n",
      "Best ROC-AUC: 0.7057\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9812395988357363), ('learning_rate', 0.04379601878774362), ('max_bin', 799), ('max_depth', 8), ('min_child_samples', 27), ('n_estimators', 28), ('num_leaves', 80), ('reg_alpha', 0.5324802854620374), ('reg_lambda', 0.1316099169492816), ('scale_pos_weight', 59)])\n",
      "\n",
      "Model #5\n",
      "Best ROC-AUC: 0.7057\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9812395988357363), ('learning_rate', 0.04379601878774362), ('max_bin', 799), ('max_depth', 8), ('min_child_samples', 27), ('n_estimators', 28), ('num_leaves', 80), ('reg_alpha', 0.5324802854620374), ('reg_lambda', 0.1316099169492816), ('scale_pos_weight', 59)])\n",
      "\n",
      "Model #6\n",
      "Best ROC-AUC: 0.7057\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9812395988357363), ('learning_rate', 0.04379601878774362), ('max_bin', 799), ('max_depth', 8), ('min_child_samples', 27), ('n_estimators', 28), ('num_leaves', 80), ('reg_alpha', 0.5324802854620374), ('reg_lambda', 0.1316099169492816), ('scale_pos_weight', 59)])\n",
      "\n",
      "Model #7\n",
      "Best ROC-AUC: 0.7057\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9812395988357363), ('learning_rate', 0.04379601878774362), ('max_bin', 799), ('max_depth', 8), ('min_child_samples', 27), ('n_estimators', 28), ('num_leaves', 80), ('reg_alpha', 0.5324802854620374), ('reg_lambda', 0.1316099169492816), ('scale_pos_weight', 59)])\n",
      "\n",
      "Model #8\n",
      "Best ROC-AUC: 0.7057\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9812395988357363), ('learning_rate', 0.04379601878774362), ('max_bin', 799), ('max_depth', 8), ('min_child_samples', 27), ('n_estimators', 28), ('num_leaves', 80), ('reg_alpha', 0.5324802854620374), ('reg_lambda', 0.1316099169492816), ('scale_pos_weight', 59)])\n",
      "\n",
      "Model #9\n",
      "Best ROC-AUC: 0.7114\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9955477986309929), ('learning_rate', 0.17545473971072012), ('max_bin', 936), ('max_depth', 5), ('min_child_samples', 20), ('n_estimators', 50), ('num_leaves', 20), ('reg_alpha', 5.091607020391696e-06), ('reg_lambda', 8.785958264239104e-05), ('scale_pos_weight', 27)])\n",
      "\n",
      "Model #10\n",
      "Best ROC-AUC: 0.7114\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9955477986309929), ('learning_rate', 0.17545473971072012), ('max_bin', 936), ('max_depth', 5), ('min_child_samples', 20), ('n_estimators', 50), ('num_leaves', 20), ('reg_alpha', 5.091607020391696e-06), ('reg_lambda', 8.785958264239104e-05), ('scale_pos_weight', 27)])\n",
      "\n",
      "Model #11\n",
      "Best ROC-AUC: 0.7534\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 1000), ('max_depth', 10), ('min_child_samples', 1), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 5.038385289147379e-07), ('reg_lambda', 1.0), ('scale_pos_weight', 54)])\n",
      "\n",
      "Model #12\n",
      "Best ROC-AUC: 0.7534\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 1000), ('max_depth', 10), ('min_child_samples', 1), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 5.038385289147379e-07), ('reg_lambda', 1.0), ('scale_pos_weight', 54)])\n",
      "\n",
      "Model #13\n",
      "Best ROC-AUC: 0.7581\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9201189228338266), ('learning_rate', 0.001), ('max_bin', 1000), ('max_depth', 10), ('min_child_samples', 11), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 8.052242268607796e-07), ('reg_lambda', 1.0), ('scale_pos_weight', 1)])\n",
      "\n",
      "Model #14\n",
      "Best ROC-AUC: 0.7581\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9201189228338266), ('learning_rate', 0.001), ('max_bin', 1000), ('max_depth', 10), ('min_child_samples', 11), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 8.052242268607796e-07), ('reg_lambda', 1.0), ('scale_pos_weight', 1)])\n",
      "\n",
      "Model #15\n",
      "Best ROC-AUC: 0.7595\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 769), ('max_depth', 7), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 10.0), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #16\n",
      "Best ROC-AUC: 0.7595\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 769), ('max_depth', 7), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 10.0), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #17\n",
      "Best ROC-AUC: 0.7595\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 769), ('max_depth', 7), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 10.0), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #18\n",
      "Best ROC-AUC: 0.7595\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 769), ('max_depth', 7), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 10.0), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #19\n",
      "Best ROC-AUC: 0.7595\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 769), ('max_depth', 7), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 10.0), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #20\n",
      "Best ROC-AUC: 0.7595\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 769), ('max_depth', 7), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 10.0), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #21\n",
      "Best ROC-AUC: 0.7595\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 769), ('max_depth', 7), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 10.0), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #22\n",
      "Best ROC-AUC: 0.7595\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 769), ('max_depth', 7), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 10.0), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #23\n",
      "Best ROC-AUC: 0.7595\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 769), ('max_depth', 7), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 10.0), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #24\n",
      "Best ROC-AUC: 0.7595\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 769), ('max_depth', 7), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 10.0), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #25\n",
      "Best ROC-AUC: 0.7612\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 1000), ('max_depth', 10), ('min_child_samples', 38), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 10.0), ('reg_lambda', 1e-10), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #26\n",
      "Best ROC-AUC: 0.7612\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 1000), ('max_depth', 10), ('min_child_samples', 38), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 10.0), ('reg_lambda', 1e-10), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #27\n",
      "Best ROC-AUC: 0.7612\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 1000), ('max_depth', 10), ('min_child_samples', 38), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 10.0), ('reg_lambda', 1e-10), ('scale_pos_weight', 150)])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #28\n",
      "Best ROC-AUC: 0.7612\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 1000), ('max_depth', 10), ('min_child_samples', 38), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 10.0), ('reg_lambda', 1e-10), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #29\n",
      "Best ROC-AUC: 0.7612\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 1000), ('max_depth', 10), ('min_child_samples', 38), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 10.0), ('reg_lambda', 1e-10), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #30\n",
      "Best ROC-AUC: 0.7612\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 1000), ('max_depth', 10), ('min_child_samples', 38), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 10.0), ('reg_lambda', 1e-10), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #31\n",
      "Best ROC-AUC: 0.7612\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 1000), ('max_depth', 10), ('min_child_samples', 38), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 10.0), ('reg_lambda', 1e-10), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #32\n",
      "Best ROC-AUC: 0.7612\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 1000), ('max_depth', 10), ('min_child_samples', 38), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 10.0), ('reg_lambda', 1e-10), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #33\n",
      "Best ROC-AUC: 0.7612\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 1000), ('max_depth', 10), ('min_child_samples', 38), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 10.0), ('reg_lambda', 1e-10), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #34\n",
      "Best ROC-AUC: 0.7634\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 930), ('max_depth', 10), ('min_child_samples', 40), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #35\n",
      "Best ROC-AUC: 0.7634\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 930), ('max_depth', 10), ('min_child_samples', 40), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #36\n",
      "Best ROC-AUC: 0.7634\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 930), ('max_depth', 10), ('min_child_samples', 40), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #37\n",
      "Best ROC-AUC: 0.7634\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 930), ('max_depth', 10), ('min_child_samples', 40), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #38\n",
      "Best ROC-AUC: 0.7634\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 930), ('max_depth', 10), ('min_child_samples', 40), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #39\n",
      "Best ROC-AUC: 0.7634\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 930), ('max_depth', 10), ('min_child_samples', 40), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #40\n",
      "Best ROC-AUC: 0.7634\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 930), ('max_depth', 10), ('min_child_samples', 40), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #41\n",
      "Best ROC-AUC: 0.7634\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 930), ('max_depth', 10), ('min_child_samples', 40), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #42\n",
      "Best ROC-AUC: 0.7634\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 930), ('max_depth', 10), ('min_child_samples', 40), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #43\n",
      "Best ROC-AUC: 0.7634\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.001), ('max_bin', 930), ('max_depth', 10), ('min_child_samples', 40), ('n_estimators', 10), ('num_leaves', 20), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #44\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n",
      "Model #45\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n",
      "Model #46\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n",
      "Model #47\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n",
      "Model #48\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n",
      "Model #49\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n",
      "Model #50\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n",
      "Model #51\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n",
      "Model #52\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n",
      "Model #53\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n",
      "Model #54\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #55\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n",
      "Model #56\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n",
      "Model #57\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n",
      "Model #58\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n",
      "Model #59\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n",
      "Model #60\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n",
      "Model #61\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n",
      "Model #62\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n",
      "Model #63\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n",
      "Model #64\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n",
      "Model #65\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n",
      "Model #66\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
      "\n",
      "Model #67\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #68\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #69\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #70\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #71\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #72\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #73\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #74\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #75\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #76\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #77\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #78\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #79\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #80\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #81\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #82\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #83\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #84\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #85\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #86\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #87\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #88\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #89\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #90\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #91\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #92\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #93\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #94\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #95\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #96\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #97\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #98\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #99\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #100\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #101\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #102\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #103\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #104\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #105\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #106\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #107\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #108\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #109\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #110\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #111\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #112\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #113\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #114\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #115\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #116\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #117\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #118\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #119\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #120\n",
      "Best ROC-AUC: 0.7644\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])\n",
      "\n",
      "Model #121\n",
      "Best ROC-AUC: 0.765\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.08828356043455235), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 9.77449859052246e-07), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #122\n",
      "Best ROC-AUC: 0.765\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.08828356043455235), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 9.77449859052246e-07), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #123\n",
      "Best ROC-AUC: 0.765\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.08828356043455235), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 9.77449859052246e-07), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #124\n",
      "Best ROC-AUC: 0.765\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.08828356043455235), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 9.77449859052246e-07), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #125\n",
      "Best ROC-AUC: 0.765\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.08828356043455235), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 9.77449859052246e-07), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #126\n",
      "Best ROC-AUC: 0.765\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.08828356043455235), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 9.77449859052246e-07), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #127\n",
      "Best ROC-AUC: 0.765\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.08828356043455235), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 9.77449859052246e-07), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #128\n",
      "Best ROC-AUC: 0.765\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.08828356043455235), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 9.77449859052246e-07), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #129\n",
      "Best ROC-AUC: 0.765\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.08828356043455235), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 9.77449859052246e-07), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #130\n",
      "Best ROC-AUC: 0.765\n",
      "Best params: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.08828356043455235), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 9.77449859052246e-07), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #131\n",
      "Best ROC-AUC: 0.7651\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9067157568436548), ('learning_rate', 0.06705000834338895), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 10.0), ('reg_lambda', 0.0002699247387376386), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #132\n",
      "Best ROC-AUC: 0.7651\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9067157568436548), ('learning_rate', 0.06705000834338895), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 10.0), ('reg_lambda', 0.0002699247387376386), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #133\n",
      "Best ROC-AUC: 0.7651\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9067157568436548), ('learning_rate', 0.06705000834338895), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 10.0), ('reg_lambda', 0.0002699247387376386), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #134\n",
      "Best ROC-AUC: 0.7651\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9067157568436548), ('learning_rate', 0.06705000834338895), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 10.0), ('reg_lambda', 0.0002699247387376386), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #135\n",
      "Best ROC-AUC: 0.7651\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9067157568436548), ('learning_rate', 0.06705000834338895), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 10.0), ('reg_lambda', 0.0002699247387376386), ('scale_pos_weight', 150)])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #136\n",
      "Best ROC-AUC: 0.7651\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9067157568436548), ('learning_rate', 0.06705000834338895), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 10.0), ('reg_lambda', 0.0002699247387376386), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #137\n",
      "Best ROC-AUC: 0.7651\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9067157568436548), ('learning_rate', 0.06705000834338895), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 10.0), ('reg_lambda', 0.0002699247387376386), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #138\n",
      "Best ROC-AUC: 0.7651\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9067157568436548), ('learning_rate', 0.06705000834338895), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 10.0), ('reg_lambda', 0.0002699247387376386), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #139\n",
      "Best ROC-AUC: 0.7651\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9067157568436548), ('learning_rate', 0.06705000834338895), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 10.0), ('reg_lambda', 0.0002699247387376386), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #140\n",
      "Best ROC-AUC: 0.7651\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9067157568436548), ('learning_rate', 0.06705000834338895), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 10.0), ('reg_lambda', 0.0002699247387376386), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #141\n",
      "Best ROC-AUC: 0.7651\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9067157568436548), ('learning_rate', 0.06705000834338895), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 10.0), ('reg_lambda', 0.0002699247387376386), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #142\n",
      "Best ROC-AUC: 0.7651\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9067157568436548), ('learning_rate', 0.06705000834338895), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 10.0), ('reg_lambda', 0.0002699247387376386), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #143\n",
      "Best ROC-AUC: 0.7651\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9067157568436548), ('learning_rate', 0.06705000834338895), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 10.0), ('reg_lambda', 0.0002699247387376386), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #144\n",
      "Best ROC-AUC: 0.7651\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9067157568436548), ('learning_rate', 0.06705000834338895), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 10.0), ('reg_lambda', 0.0002699247387376386), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #145\n",
      "Best ROC-AUC: 0.7651\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9067157568436548), ('learning_rate', 0.06705000834338895), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 10.0), ('reg_lambda', 0.0002699247387376386), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #146\n",
      "Best ROC-AUC: 0.7651\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9067157568436548), ('learning_rate', 0.06705000834338895), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 10.0), ('reg_lambda', 0.0002699247387376386), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #147\n",
      "Best ROC-AUC: 0.7651\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9067157568436548), ('learning_rate', 0.06705000834338895), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 10.0), ('reg_lambda', 0.0002699247387376386), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #148\n",
      "Best ROC-AUC: 0.7651\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9067157568436548), ('learning_rate', 0.06705000834338895), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 10.0), ('reg_lambda', 0.0002699247387376386), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #149\n",
      "Best ROC-AUC: 0.7651\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9067157568436548), ('learning_rate', 0.06705000834338895), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 10.0), ('reg_lambda', 0.0002699247387376386), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #150\n",
      "Best ROC-AUC: 0.7651\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9067157568436548), ('learning_rate', 0.06705000834338895), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 10.0), ('reg_lambda', 0.0002699247387376386), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #151\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #152\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #153\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #154\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #155\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #156\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #157\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #158\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #159\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #160\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #161\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #162\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #163\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #164\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #165\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #166\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #167\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #168\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #169\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #170\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #171\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #172\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #173\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #174\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #175\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #176\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #177\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #178\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #179\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #180\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #181\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #182\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #183\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #184\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #185\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #186\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #187\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #188\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #189\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #190\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #191\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #192\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #193\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #194\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #195\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #196\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #197\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #198\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #199\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "Model #200\n",
      "Best ROC-AUC: 0.7688\n",
      "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.09643003862369257), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 50), ('n_estimators', 10), ('num_leaves', 100), ('reg_alpha', 0.8796958374226569), ('reg_lambda', 1.0), ('scale_pos_weight', 150)])\n",
      "\n",
      "CPU times: user 2h 16min 35s, sys: 2min 6s, total: 2h 18min 41s\n",
      "Wall time: 2h 19min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_lgbm = bayes_cv_tuner_lgbm.fit(mailout_train_minmax, target,callback=print_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best params: 0.76 OrderedDict([('colsample_bytree', 0.9238574532834115), ('learning_rate', 0.01), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 40), ('num_leaves', 89), ('reg_alpha', 10.0), ('reg_lambda', 0.02596034024971144), ('scale_pos_weight', 80)])\n",
    "\n",
    "\n",
    "Model #50\n",
    "Best ROC-AUC: 0.7644\n",
    "Best params: OrderedDict([('colsample_bytree', 0.946913879853184), ('learning_rate', 0.04799599894049769), ('max_bin', 1000), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 28), ('num_leaves', 100), ('reg_alpha', 5.432508975487921e-09), ('reg_lambda', 5.280547754951558e-07), ('scale_pos_weight', 22)])\n",
    "\n",
    "Model #102\n",
    "Best ROC-AUC: 0.7644\n",
    "Best params: OrderedDict([('colsample_bytree', 0.9), ('learning_rate', 0.06184798151304283), ('max_bin', 752), ('max_depth', 2), ('min_child_samples', 1), ('n_estimators', 74), ('num_leaves', 100), ('reg_alpha', 1e-09), ('reg_lambda', 1e-10), ('scale_pos_weight', 34)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(application='binary', colsample_bytree=0.9,\n",
       "               learning_rate=0.09643003862369257, max_bin=1000, max_depth=2,\n",
       "               metric='auc', min_child_samples=50, n_estimators=10,\n",
       "               num_leaves=100, reg_alpha=0.8796958374226569, reg_lambda=1.0,\n",
       "               scale_pos_weight=150, verbose=-1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_lgbm = bayes_cv_tuner_lgbm.best_estimator_\n",
    "bayes_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(application='binary', colsample_bytree=0.9,\n",
       "               learning_rate=0.09643003862369257, max_bin=1000, max_depth=2,\n",
       "               metric='auc', min_child_samples=50, n_estimators=10,\n",
       "               num_leaves=100, reg_alpha=0.8796958374226569, reg_lambda=1.0,\n",
       "               scale_pos_weight=150, verbose=-1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_lgbm.fit(mailout_train_minmax, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lgbm_200.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(bayes_lgbm, 'lgbm_200.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning of GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS = 50\n",
    "SEED = 42\n",
    "bayes_cv_tuner_gb = BayesSearchCV(\n",
    "    estimator = GradientBoostingClassifier(\n",
    "        #application='binary',\n",
    "        #criterion='auc',\n",
    "        #n_jobs=-1,\n",
    "        #verbose=-1,\n",
    "    ),\n",
    "    search_spaces = {\n",
    "        'learning_rate': (0.001, 0.25, 'uniform'),\n",
    "        'n_estimators': (50, 2000),\n",
    "        'max_depth': (2, 10),\n",
    "        'min_samples_split':(2, 100),\n",
    "        'min_samples_leaf': (1, 10),\n",
    "        'max_features': (10, 30),\n",
    "        'subsample':(0.7, 1.0),\n",
    "},    \n",
    "    scoring = 'roc_auc',\n",
    "    cv = StratifiedKFold(\n",
    "        n_splits=5,\n",
    "        shuffle=True,\n",
    "        random_state=SEED\n",
    "    ),\n",
    "    n_jobs = -1,\n",
    "    n_iter = ITERATIONS,  \n",
    "    #verbose = 0,\n",
    "    refit = True,\n",
    "    random_state = SEED\n",
    ")\n",
    "\n",
    "def print_param(x):\n",
    "    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
    "    \n",
    "    # Get all the models tested so far in DataFrame format\n",
    "    all_models = pd.DataFrame(bayes_cv_tuner_gb.cv_results_)    \n",
    "    \n",
    "    # Get current parameters and the best parameters    \n",
    "    best_params = pd.Series(bayes_cv_tuner_gb.best_params_)\n",
    "    print('Model #{}\\nBest ROC-AUC: {}\\nBest params: {}\\n'.format(\n",
    "        len(all_models),\n",
    "        np.round(bayes_cv_tuner_gb.best_score_, 4),\n",
    "        bayes_cv_tuner_gb.best_params_\n",
    "    ))\n",
    "    \n",
    "    # Save all model results\n",
    "    clf_name = bayes_cv_tuner_gb.estimator.__class__.__name__\n",
    "    all_models.to_csv(clf_name+\"_cv_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #1\n",
      "Best ROC-AUC: 0.6413\n",
      "Best params: OrderedDict([('learning_rate', 0.10311588575447515), ('max_depth', 8), ('max_features', 29), ('min_samples_leaf', 4), ('min_samples_split', 68), ('n_estimators', 858), ('subsample', 0.8052794004697432)])\n",
      "\n",
      "Model #2\n",
      "Best ROC-AUC: 0.6469\n",
      "Best params: OrderedDict([('learning_rate', 0.20950970053276782), ('max_depth', 9), ('max_features', 16), ('min_samples_leaf', 10), ('min_samples_split', 87), ('n_estimators', 172), ('subsample', 0.7414925614835726)])\n",
      "\n",
      "Model #3\n",
      "Best ROC-AUC: 0.6469\n",
      "Best params: OrderedDict([('learning_rate', 0.20950970053276782), ('max_depth', 9), ('max_features', 16), ('min_samples_leaf', 10), ('min_samples_split', 87), ('n_estimators', 172), ('subsample', 0.7414925614835726)])\n",
      "\n",
      "Model #4\n",
      "Best ROC-AUC: 0.709\n",
      "Best params: OrderedDict([('learning_rate', 0.20328660110098348), ('max_depth', 3), ('max_features', 22), ('min_samples_leaf', 8), ('min_samples_split', 53), ('n_estimators', 236), ('subsample', 0.9267401598507645)])\n",
      "\n",
      "Model #5\n",
      "Best ROC-AUC: 0.709\n",
      "Best params: OrderedDict([('learning_rate', 0.20328660110098348), ('max_depth', 3), ('max_features', 22), ('min_samples_leaf', 8), ('min_samples_split', 53), ('n_estimators', 236), ('subsample', 0.9267401598507645)])\n",
      "\n",
      "Model #6\n",
      "Best ROC-AUC: 0.709\n",
      "Best params: OrderedDict([('learning_rate', 0.20328660110098348), ('max_depth', 3), ('max_features', 22), ('min_samples_leaf', 8), ('min_samples_split', 53), ('n_estimators', 236), ('subsample', 0.9267401598507645)])\n",
      "\n",
      "Model #7\n",
      "Best ROC-AUC: 0.709\n",
      "Best params: OrderedDict([('learning_rate', 0.20328660110098348), ('max_depth', 3), ('max_features', 22), ('min_samples_leaf', 8), ('min_samples_split', 53), ('n_estimators', 236), ('subsample', 0.9267401598507645)])\n",
      "\n",
      "Model #8\n",
      "Best ROC-AUC: 0.709\n",
      "Best params: OrderedDict([('learning_rate', 0.20328660110098348), ('max_depth', 3), ('max_features', 22), ('min_samples_leaf', 8), ('min_samples_split', 53), ('n_estimators', 236), ('subsample', 0.9267401598507645)])\n",
      "\n",
      "Model #9\n",
      "Best ROC-AUC: 0.709\n",
      "Best params: OrderedDict([('learning_rate', 0.20328660110098348), ('max_depth', 3), ('max_features', 22), ('min_samples_leaf', 8), ('min_samples_split', 53), ('n_estimators', 236), ('subsample', 0.9267401598507645)])\n",
      "\n",
      "Model #10\n",
      "Best ROC-AUC: 0.7403\n",
      "Best params: OrderedDict([('learning_rate', 0.0019039465064310634), ('max_depth', 9), ('max_features', 25), ('min_samples_leaf', 3), ('min_samples_split', 59), ('n_estimators', 586), ('subsample', 0.7938517918703885)])\n",
      "\n",
      "Model #11\n",
      "Best ROC-AUC: 0.7403\n",
      "Best params: OrderedDict([('learning_rate', 0.0019039465064310634), ('max_depth', 9), ('max_features', 25), ('min_samples_leaf', 3), ('min_samples_split', 59), ('n_estimators', 586), ('subsample', 0.7938517918703885)])\n",
      "\n",
      "Model #12\n",
      "Best ROC-AUC: 0.7403\n",
      "Best params: OrderedDict([('learning_rate', 0.0019039465064310634), ('max_depth', 9), ('max_features', 25), ('min_samples_leaf', 3), ('min_samples_split', 59), ('n_estimators', 586), ('subsample', 0.7938517918703885)])\n",
      "\n",
      "Model #13\n",
      "Best ROC-AUC: 0.7403\n",
      "Best params: OrderedDict([('learning_rate', 0.0019039465064310634), ('max_depth', 9), ('max_features', 25), ('min_samples_leaf', 3), ('min_samples_split', 59), ('n_estimators', 586), ('subsample', 0.7938517918703885)])\n",
      "\n",
      "Model #14\n",
      "Best ROC-AUC: 0.7403\n",
      "Best params: OrderedDict([('learning_rate', 0.0019039465064310634), ('max_depth', 9), ('max_features', 25), ('min_samples_leaf', 3), ('min_samples_split', 59), ('n_estimators', 586), ('subsample', 0.7938517918703885)])\n",
      "\n",
      "Model #15\n",
      "Best ROC-AUC: 0.7403\n",
      "Best params: OrderedDict([('learning_rate', 0.0019039465064310634), ('max_depth', 9), ('max_features', 25), ('min_samples_leaf', 3), ('min_samples_split', 59), ('n_estimators', 586), ('subsample', 0.7938517918703885)])\n",
      "\n",
      "Model #16\n",
      "Best ROC-AUC: 0.7435\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 9), ('max_features', 27), ('min_samples_leaf', 1), ('min_samples_split', 57), ('n_estimators', 907), ('subsample', 0.760675625302384)])\n",
      "\n",
      "Model #17\n",
      "Best ROC-AUC: 0.7435\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 9), ('max_features', 27), ('min_samples_leaf', 1), ('min_samples_split', 57), ('n_estimators', 907), ('subsample', 0.760675625302384)])\n",
      "\n",
      "Model #18\n",
      "Best ROC-AUC: 0.7467\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 10), ('max_features', 30), ('min_samples_leaf', 1), ('min_samples_split', 84), ('n_estimators', 1143), ('subsample', 0.7931957324118105)])\n",
      "\n",
      "Model #19\n",
      "Best ROC-AUC: 0.7467\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 10), ('max_features', 30), ('min_samples_leaf', 1), ('min_samples_split', 84), ('n_estimators', 1143), ('subsample', 0.7931957324118105)])\n",
      "\n",
      "Model #20\n",
      "Best ROC-AUC: 0.7467\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 10), ('max_features', 30), ('min_samples_leaf', 1), ('min_samples_split', 84), ('n_estimators', 1143), ('subsample', 0.7931957324118105)])\n",
      "\n",
      "Model #21\n",
      "Best ROC-AUC: 0.7467\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 10), ('max_features', 30), ('min_samples_leaf', 1), ('min_samples_split', 84), ('n_estimators', 1143), ('subsample', 0.7931957324118105)])\n",
      "\n",
      "Model #22\n",
      "Best ROC-AUC: 0.7467\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 10), ('max_features', 30), ('min_samples_leaf', 1), ('min_samples_split', 84), ('n_estimators', 1143), ('subsample', 0.7931957324118105)])\n",
      "\n",
      "Model #23\n",
      "Best ROC-AUC: 0.7467\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 10), ('max_features', 30), ('min_samples_leaf', 1), ('min_samples_split', 84), ('n_estimators', 1143), ('subsample', 0.7931957324118105)])\n",
      "\n",
      "Model #24\n",
      "Best ROC-AUC: 0.7467\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 10), ('max_features', 30), ('min_samples_leaf', 1), ('min_samples_split', 84), ('n_estimators', 1143), ('subsample', 0.7931957324118105)])\n",
      "\n",
      "Model #25\n",
      "Best ROC-AUC: 0.7467\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 10), ('max_features', 30), ('min_samples_leaf', 1), ('min_samples_split', 84), ('n_estimators', 1143), ('subsample', 0.7931957324118105)])\n",
      "\n",
      "Model #26\n",
      "Best ROC-AUC: 0.7467\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 10), ('max_features', 30), ('min_samples_leaf', 1), ('min_samples_split', 84), ('n_estimators', 1143), ('subsample', 0.7931957324118105)])\n",
      "\n",
      "Model #27\n",
      "Best ROC-AUC: 0.7501\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 8), ('max_features', 30), ('min_samples_leaf', 1), ('min_samples_split', 100), ('n_estimators', 2000), ('subsample', 0.7)])\n",
      "\n",
      "Model #28\n",
      "Best ROC-AUC: 0.7501\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 8), ('max_features', 30), ('min_samples_leaf', 1), ('min_samples_split', 100), ('n_estimators', 2000), ('subsample', 0.7)])\n",
      "\n",
      "Model #29\n",
      "Best ROC-AUC: 0.7501\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 8), ('max_features', 30), ('min_samples_leaf', 1), ('min_samples_split', 100), ('n_estimators', 2000), ('subsample', 0.7)])\n",
      "\n",
      "Model #30\n",
      "Best ROC-AUC: 0.7501\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 8), ('max_features', 30), ('min_samples_leaf', 1), ('min_samples_split', 100), ('n_estimators', 2000), ('subsample', 0.7)])\n",
      "\n",
      "Model #31\n",
      "Best ROC-AUC: 0.7501\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 8), ('max_features', 30), ('min_samples_leaf', 1), ('min_samples_split', 100), ('n_estimators', 2000), ('subsample', 0.7)])\n",
      "\n",
      "Model #32\n",
      "Best ROC-AUC: 0.7501\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 8), ('max_features', 30), ('min_samples_leaf', 1), ('min_samples_split', 100), ('n_estimators', 2000), ('subsample', 0.7)])\n",
      "\n",
      "Model #33\n",
      "Best ROC-AUC: 0.7501\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 8), ('max_features', 30), ('min_samples_leaf', 1), ('min_samples_split', 100), ('n_estimators', 2000), ('subsample', 0.7)])\n",
      "\n",
      "Model #34\n",
      "Best ROC-AUC: 0.7521\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 6), ('max_features', 30), ('min_samples_leaf', 10), ('min_samples_split', 2), ('n_estimators', 2000), ('subsample', 0.7195263583720765)])\n",
      "\n",
      "Model #35\n",
      "Best ROC-AUC: 0.7521\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 6), ('max_features', 30), ('min_samples_leaf', 10), ('min_samples_split', 2), ('n_estimators', 2000), ('subsample', 0.7195263583720765)])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #36\n",
      "Best ROC-AUC: 0.7521\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 6), ('max_features', 30), ('min_samples_leaf', 10), ('min_samples_split', 2), ('n_estimators', 2000), ('subsample', 0.7195263583720765)])\n",
      "\n",
      "Model #37\n",
      "Best ROC-AUC: 0.7521\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 6), ('max_features', 30), ('min_samples_leaf', 10), ('min_samples_split', 2), ('n_estimators', 2000), ('subsample', 0.7195263583720765)])\n",
      "\n",
      "Model #38\n",
      "Best ROC-AUC: 0.7521\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 6), ('max_features', 30), ('min_samples_leaf', 10), ('min_samples_split', 2), ('n_estimators', 2000), ('subsample', 0.7195263583720765)])\n",
      "\n",
      "Model #39\n",
      "Best ROC-AUC: 0.7521\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 6), ('max_features', 30), ('min_samples_leaf', 10), ('min_samples_split', 2), ('n_estimators', 2000), ('subsample', 0.7195263583720765)])\n",
      "\n",
      "Model #40\n",
      "Best ROC-AUC: 0.7521\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 6), ('max_features', 30), ('min_samples_leaf', 10), ('min_samples_split', 2), ('n_estimators', 2000), ('subsample', 0.7195263583720765)])\n",
      "\n",
      "Model #41\n",
      "Best ROC-AUC: 0.7521\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 6), ('max_features', 30), ('min_samples_leaf', 10), ('min_samples_split', 2), ('n_estimators', 2000), ('subsample', 0.7195263583720765)])\n",
      "\n",
      "Model #42\n",
      "Best ROC-AUC: 0.7521\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 6), ('max_features', 30), ('min_samples_leaf', 10), ('min_samples_split', 2), ('n_estimators', 2000), ('subsample', 0.7195263583720765)])\n",
      "\n",
      "Model #43\n",
      "Best ROC-AUC: 0.7521\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 6), ('max_features', 30), ('min_samples_leaf', 10), ('min_samples_split', 2), ('n_estimators', 2000), ('subsample', 0.7195263583720765)])\n",
      "\n",
      "Model #44\n",
      "Best ROC-AUC: 0.7521\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 6), ('max_features', 30), ('min_samples_leaf', 10), ('min_samples_split', 2), ('n_estimators', 2000), ('subsample', 0.7195263583720765)])\n",
      "\n",
      "Model #45\n",
      "Best ROC-AUC: 0.7521\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 6), ('max_features', 30), ('min_samples_leaf', 10), ('min_samples_split', 2), ('n_estimators', 2000), ('subsample', 0.7195263583720765)])\n",
      "\n",
      "Model #46\n",
      "Best ROC-AUC: 0.7521\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 6), ('max_features', 30), ('min_samples_leaf', 10), ('min_samples_split', 2), ('n_estimators', 2000), ('subsample', 0.7195263583720765)])\n",
      "\n",
      "Model #47\n",
      "Best ROC-AUC: 0.7521\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 6), ('max_features', 30), ('min_samples_leaf', 10), ('min_samples_split', 2), ('n_estimators', 2000), ('subsample', 0.7195263583720765)])\n",
      "\n",
      "Model #48\n",
      "Best ROC-AUC: 0.7521\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 6), ('max_features', 30), ('min_samples_leaf', 10), ('min_samples_split', 2), ('n_estimators', 2000), ('subsample', 0.7195263583720765)])\n",
      "\n",
      "Model #49\n",
      "Best ROC-AUC: 0.7521\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 6), ('max_features', 30), ('min_samples_leaf', 10), ('min_samples_split', 2), ('n_estimators', 2000), ('subsample', 0.7195263583720765)])\n",
      "\n",
      "Model #50\n",
      "Best ROC-AUC: 0.7521\n",
      "Best params: OrderedDict([('learning_rate', 0.001), ('max_depth', 6), ('max_features', 30), ('min_samples_leaf', 10), ('min_samples_split', 2), ('n_estimators', 2000), ('subsample', 0.7195263583720765)])\n",
      "\n",
      "CPU times: user 4h 53min 23s, sys: 10.1 s, total: 4h 53min 33s\n",
      "Wall time: 4h 56min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_gb = bayes_cv_tuner_gb.fit(mailout_train_minmax, target,callback=print_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.001, max_depth=6, max_features=30,\n",
       "                           min_samples_leaf=10, n_estimators=2000,\n",
       "                           subsample=0.7195263583720765)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_gb = bayes_cv_tuner_gb.best_estimator_\n",
    "bayes_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.001, max_depth=6, max_features=30,\n",
       "                           min_samples_leaf=10, n_estimators=2000,\n",
       "                           subsample=0.7195263583720765)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_gb.fit(mailout_train_minmax, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gb_50.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(bayes_lgbm, 'gb_50.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
